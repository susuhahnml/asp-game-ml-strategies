[
    {
        "command": "plot --game-name=dom --file=dqn-random --out=dqn-random",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "console",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-random"
            ],
            "out": "dqn-random"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "dqn_rl --game-name=dom --rand=2 --out=dqn-random --train-rand=2 --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": 2,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "dqn_rl",
            "build": [
                22205.183
            ],
            "average_build": 22205.183,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=dom --rand=2 --out=dqn-strategy --train-rand=2 --nb-steps=1000 --save-every=100 --strategy-opponent=./approaches/dqn_rl/dom-asp-strategy.lp --model-name=strategy",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-strategy",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": 2,
            "model_name": "strategy",
            "vis_tree": false,
            "strategy_opponent": "./approaches/dqn_rl/dom-asp-strategy.lp"
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "dqn_rl",
            "build": [
                26568.198
            ],
            "average_build": 26568.198,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "supervised_ml --game-name=dom --rand=2 --out=supervised --n-epochs=1000 --model-name=transfer --training-file=corrected-200games-1000-iter.csv",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "supervised",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "supervised_ml",
            "architecture_name": "default",
            "n_epochs": 1000,
            "model_name": "transfer",
            "training_file": "corrected-200games-1000-iter.csv"
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "supervised_ml",
            "build": [
                115718.588
            ],
            "average_build": 115718.588,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=dom --rand=2 --out=alpha-not-penalized --train-rand=2 --model-name=not-penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-not-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "not-penalized",
            "train_rand": 2,
            "vis_tree": false
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "alpha_zero",
            "build": [
                89947.099
            ],
            "average_build": 89947.099,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=dom --rand=2 --out=alpha-penalized --train-rand=2 --model-name=penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300 --penalize-illegal",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-penalized",
            "penalize_illegal": true,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "penalized",
            "train_rand": 2,
            "vis_tree": false
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "alpha_zero",
            "build": [
                46307.314
            ],
            "average_build": 46307.314,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "plot --game-name=dom --file=dqn-random --out=dqn-random",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "console",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-random"
            ],
            "out": "dqn-random"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=dqn-strategy --out=dqn-strategy",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "console",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-strategy"
            ],
            "out": "dqn-strategy"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=supervised-transfer --out=supervised-transfer",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "console",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "supervised-transfer"
            ],
            "out": "supervised-transfer"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=supervised-transfer --out=supervised-transfer",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "console",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "supervised-transfer"
            ],
            "out": "supervised-transfer"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=alpha-zero-not-penalized --out=alpha-zero-not-penalized",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "console",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "alpha-zero-not-penalized"
            ],
            "out": "alpha-zero-not-penalized"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=alpha-zero-penalized --out=alpha-zero-penalized",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "console",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "alpha-zero-penalized"
            ],
            "out": "alpha-zero-penalized"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=dqn-random --out=dqn-random",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-random"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=dqn-strategy --out=dqn-strategy",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-strategy",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-strategy"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=supervised-transfer --out=supervised-transfer",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "supervised-transfer",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "supervised-transfer"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=supervised-transfer --out=supervised-transfer",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "supervised-transfer",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "supervised-transfer"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=alpha-zero-not-penalized --out=alpha-zero-not-penalized",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-zero-not-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "alpha-zero-not-penalized"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=alpha-zero-penalized --out=alpha-zero-penalized",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-zero-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "alpha-zero-penalized"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=dqn-random --out=dqn-random",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-random"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=dqn-strategy --out=dqn-strategy",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-strategy",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-strategy"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=supervised-transfer --out=supervised-transfer",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "supervised-transfer",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "supervised-transfer"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=supervised-transfer --out=supervised-transfer",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "supervised-transfer",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "supervised-transfer"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=alpha-zero-not-penalized --out=alpha-zero-not-penalized",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-zero-not-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "alpha-zero-not-penalized"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "plot --game-name=dom --file=alpha-zero-penalized --out=alpha-zero-penalized",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-zero-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "alpha-zero-penalized"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).in_hand(a,domino(1,2)).in_hand(a,domino(1,3)).in_hand(a,domino(2,3)).in_hand(b,domino(0,1)).in_hand(b,domino(0,2)).in_hand(b,domino(0,3)).stack(l,3).stack(r,3)",
        "results": {}
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-random --train-rand=2 --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": 2,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "control(a).has(1,0).has(2,2).has(3,2).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                20488.881
            ],
            "average_build": 20488.881,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-random --train-rand=2 --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": 2,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "control(a).has(1,0).has(2,2).has(3,2).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                21108.808
            ],
            "average_build": 21108.808,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-strategy --train-rand=2 --nb-steps=1000 --save-every=100 --strategy-opponent=./approaches/dqn_rl/dom-asp-strategy.lp --model-name=strategy",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-strategy",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": 2,
            "model_name": "strategy",
            "vis_tree": false,
            "strategy_opponent": "./approaches/dqn_rl/dom-asp-strategy.lp"
        },
        "initial_state": "control(a).has(1,0).has(2,2).has(3,2).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                20715.016
            ],
            "average_build": 20715.016,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=nim --initial=default_initial.lp --out=alpha-not-penalized --train-rand=2 --model-name=not-penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-not-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "not-penalized",
            "train_rand": 2,
            "vis_tree": false
        },
        "initial_state": "control(a).has(1,4).has(2,7).has(3,3)",
        "results": {
            "player": "alpha_zero",
            "build": [
                56564.1
            ],
            "average_build": 56564.1,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=nim --initial=default_initial.lp --out=alpha-penalized --train-rand=2 --model-name=penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300 --penalize-illegal",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-penalized",
            "penalize_illegal": true,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "penalized",
            "train_rand": 2,
            "vis_tree": false
        },
        "initial_state": "control(a).has(1,4).has(2,7).has(3,3)",
        "results": {
            "player": "alpha_zero",
            "build": [
                57335.366
            ],
            "average_build": 57335.366,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-random --nb-steps=1000 --save-every=100 --model-name=random --log=debug",
        "args": {
            "log": "debug",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": null,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "control(a).has(1,0).has(2,2).has(3,2).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                10645.475
            ],
            "average_build": 10645.475,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-random --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": null,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "control(a).has(1,0).has(2,2).has(3,2).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                20435.765
            ],
            "average_build": 20435.765,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "plot --game-name=nim --file=dqn-random --out=dqn-random",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "plot",
            "file": [
                "dqn-random"
            ],
            "plot_out": "plot"
        },
        "initial_state": "control(a).has(1,0).has(2,2).has(3,2).has(4,1)",
        "results": {}
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-random --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": null,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "control(a).has(1,0).has(2,2).has(3,2).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                22622.905
            ],
            "average_build": 22622.905,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=dom --rand=2 --out=dqn-random --train-rand=2 --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": 2,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "dqn_rl",
            "build": [
                21763.654
            ],
            "average_build": 21763.654,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=dom --rand=2 --out=dqn-strategy --train-rand=2 --nb-steps=1000 --save-every=100 --strategy-opponent=./approaches/dqn_rl/dom-asp-strategy.lp --model-name=strategy",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-strategy",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": 2,
            "model_name": "strategy",
            "vis_tree": false,
            "strategy_opponent": "./approaches/dqn_rl/dom-asp-strategy.lp"
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "dqn_rl",
            "build": [
                20005.531
            ],
            "average_build": 20005.531,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "supervised_ml --game-name=dom --rand=2 --out=supervised --n-epochs=1000 --model-name=transfer --training-file=corrected-200games-1000-iter.csv",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "supervised",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "supervised_ml",
            "architecture_name": "default",
            "n_epochs": 1000,
            "model_name": "transfer",
            "training_file": "corrected-200games-1000-iter.csv"
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "supervised_ml",
            "build": [
                131503.95
            ],
            "average_build": 131503.95,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=dom --rand=2 --out=alpha-not-penalized --train-rand=2 --model-name=not-penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-not-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "not-penalized",
            "train_rand": 2,
            "vis_tree": false
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "alpha_zero",
            "build": [
                108490.616
            ],
            "average_build": 108490.616,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=dom --rand=2 --out=alpha-penalized --train-rand=2 --model-name=penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300 --penalize-illegal",
        "args": {
            "log": "INFO",
            "game_name": "dom",
            "const": null,
            "random_initial_state_seed": 2,
            "initial": null,
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-penalized",
            "penalize_illegal": true,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "penalized",
            "train_rand": 2,
            "vis_tree": false
        },
        "initial_state": "RANDOM",
        "results": {
            "player": "alpha_zero",
            "build": [
                53114.644
            ],
            "average_build": 53114.644,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-random --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": null,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "control(a).has(1,0).has(2,3).has(3,3).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                18503.788
            ],
            "average_build": 18503.788,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-strategy --nb-steps=1000 --save-every=100 --strategy-opponent=./approaches/dqn_rl/dom-asp-strategy.lp --model-name=strategy",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-strategy",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": null,
            "model_name": "strategy",
            "vis_tree": false,
            "strategy_opponent": "./approaches/dqn_rl/dom-asp-strategy.lp"
        },
        "initial_state": "control(a).has(1,0).has(2,3).has(3,3).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                20103.299
            ],
            "average_build": 20103.299,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=nim --initial=default_initial.lp --out=alpha-not-penalized --model-name=not-penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-not-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "not-penalized",
            "train_rand": null,
            "vis_tree": false
        },
        "initial_state": "control(a).has(1,0).has(2,3).has(3,3).has(4,1)",
        "results": {
            "player": "alpha_zero",
            "build": [
                43503.766
            ],
            "average_build": 43503.766,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-random --nb-steps=1000 --save-every=100 --model-name=random",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-random",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": null,
            "model_name": "random",
            "vis_tree": false,
            "strategy_opponent": null
        },
        "initial_state": "control(a).has(1,0).has(2,3).has(3,3).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                19195.04
            ],
            "average_build": 19195.04,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "dqn_rl --game-name=nim --initial=default_initial.lp --out=dqn-strategy --nb-steps=1000 --save-every=100 --strategy-opponent=./approaches/dqn_rl/dom-asp-strategy.lp --model-name=strategy",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "dqn-strategy",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "dqn_rl",
            "architecture_name": "default",
            "save_every": 100,
            "nb_steps": 1000,
            "eps": 0.1,
            "train_rand": null,
            "model_name": "strategy",
            "vis_tree": false,
            "strategy_opponent": "./approaches/dqn_rl/dom-asp-strategy.lp"
        },
        "initial_state": "control(a).has(1,0).has(2,3).has(3,3).has(4,1)",
        "results": {
            "player": "dqn_rl",
            "build": [
                20366.172
            ],
            "average_build": 20366.172,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=nim --initial=default_initial.lp --out=alpha-not-penalized --model-name=not-penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-not-penalized",
            "penalize_illegal": false,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "not-penalized",
            "train_rand": null,
            "vis_tree": false
        },
        "initial_state": "control(a).has(1,0).has(2,3).has(3,3).has(4,1)",
        "results": {
            "player": "alpha_zero",
            "build": [
                53287.502
            ],
            "average_build": 53287.502,
            "std": 0.0,
            "special_results": null
        }
    },
    {
        "command": "alpha_zero --game-name=nim --initial=default_initial.lp --out=alpha-penalized --model-name=penalized --n-vs=200 --n-train=2 --n-episodes=2 --n-epochs=100 --n-mcts-simulations=300 --penalize-illegal",
        "args": {
            "log": "INFO",
            "game_name": "nim",
            "const": null,
            "random_initial_state_seed": null,
            "initial": "default_initial.lp",
            "num_repetitions": 1,
            "init_limit": null,
            "benchmark_output_file": "alpha-penalized",
            "penalize_illegal": true,
            "n_initial": null,
            "selected_approach": "alpha_zero",
            "architecture_name": "default",
            "loss": "custom",
            "n_train": 2,
            "n_episodes": 2,
            "n_epochs": 100,
            "batch_size": 200,
            "lr": 0.01,
            "n_vs": 200,
            "n_mcts_simulations": 300,
            "model_name": "penalized",
            "train_rand": null,
            "vis_tree": false
        },
        "initial_state": "control(a).has(1,0).has(2,3).has(3,3).has(4,1)",
        "results": {
            "player": "alpha_zero",
            "build": [
                34571.563
            ],
            "average_build": 34571.563,
            "std": 0.0,
            "special_results": null
        }
    }
]