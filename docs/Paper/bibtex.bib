@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/362/6419/1140},
	eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}

@article{DBLP:journals/corr/abs-1804-02477,
  author    = {Abhinav Verma and
               Vijayaraghavan Murali and
               Rishabh Singh and
               Pushmeet Kohli and
               Swarat Chaudhuri},
  title     = {Programmatically Interpretable Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1804.02477},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.02477},
  archivePrefix = {arXiv},
  eprint    = {1804.02477},
  timestamp = {Mon, 13 Aug 2018 16:47:58 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-02477.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{genesereth2005general,
  title={General game playing: Overview of the AAAI competition},
  author={Genesereth, Michael and Love, Nathaniel and Pell, Barney},
  journal={AI magazine},
  volume={26},
  number={2},
  pages={62--62},
  year={2005}
}

@article{bouton1901nim,
  title={Nim, a game with a complete mathematical theory},
  author={Bouton, Charles L},
  journal={The Annals of Mathematics},
  volume={3},
  number={1/4},
  pages={35--39},
  year={1901},
  publisher={JSTOR}
}

@article{kelly2006one,
  title={One-pile mis{\`e}re Nim for three or more players},
  author={Kelly, Annela R},
  journal={International journal of mathematics and mathematical sciences},
  volume={2006},
  year={2006},
  publisher={Hindawi}
}

@article{abu2019tic,
  title={Tic-Tac-Toe Learning Using Artificial Neural Networks},
  author={Abu Dalffa, Mohaned and Abu-Nasser, Bassem S and Abu-Naser, Samy S},
  year={2019},
  publisher={IJARW}
}

@InProceedings{10.1007/978-3-319-07890-8_12,
author="Demaine, Erik D.
and Ma, Fermi
and Waingarten, Erik",
editor="Ferro, Alfredo
and Luccio, Fabrizio
and Widmayer, Peter",
title="Playing Dominoes Is Hard, Except by Yourself",
booktitle="Fun with Algorithms",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="137--146",
abstract="Dominoes is a popular and well-known game possibly dating back three millennia. Players are given a set of domino tiles, each with two labeled square faces, and take turns connecting them into a growing chain of dominoes by matching identical faces. We show that single-player dominoes is in P, while multiplayer dominoes is hard: when players cooperate, the game is NP-complete, and when players compete, the game is PSPACE-complete. In addition, we show that these hardness results easily extend to games involving team play.",
isbn="978-3-319-07890-8"
}

@book{lifschitz2019answer,
  title={Answer set programming},
  author={Lifschitz, Vladimir},
  year={2019},
  publisher={Springer International Publishing}
}

@article{gebser2014clingo,
  title={Clingo= ASP+ control: Preliminary report},
  author={Gebser, Martin and Kaminski, Roland and Kaufmann, Benjamin and Schaub, Torsten},
  journal={arXiv preprint arXiv:1405.3694},
  year={2014}
}

@misc {ILASP_system,
  author = "Law, Mark and Russo, Alessandra and Broda, Krysia",
  title  = "The {ILASP} system for learning Answer Set Programs",
  year   = "2015",
  howpublished={\url{www.ilasp.com}}
}

@misc{law2017inductive,
  title={Inductive learning of answer set programs v3. 1.0},
  author={Law, Mark and Russo, Alessandra and Broda, Krysia},
  year={2017}
}

@article{love@ggp,
  title={General Game Playing: Game Description Language Specification},
  author={Love, Nathaniel and Hinrichs,Timothy and Haley, David and  Schkufza, Eric and Genesereth, Michael},
  journal={Stanford University},
  year={2008}
}

@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Malaysia; Pearson Education Limited,}
}


@article{Gelfond1991,
	Abstract = {An important limitation of traditional logic programming as a knowledge representation tool, in comparison with classical logic, is that logic programming does not allow us to deal directly with incomplete information. In order to overcome this limitation, we extend the class of general logic programs by including classical negation, in addition to negation-as-failure. The semantics of such extended programs is based on the method of stable models. The concept of a disjunctive database can be extended in a similar way. We show that some facts of commonsense knowledge can be represented by logic programs and disjunctive databases more easily when classical negation is available. Computationally, classical negation can be eliminated from extended programs by a simple preprocessor. Extended programs are identical to a special case of default theories in the sense of Reiter.},
	Author = {Gelfond, Michael and Lifschitz, Vladimir},
	Day = {01},
	Doi = {10.1007/BF03037169},
	Issn = {1882-7055},
	Journal = {New Generation Computing},
	Month = {Aug},
	Number = {3},
	Pages = {365--385},
	Title = {Classical negation in logic programs and disjunctive databases},
	Url = {https://doi.org/10.1007/BF03037169},
	Volume = {9},
	Year = {1991},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF03037169},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/BF03037169}
  }
@article{GlimpsASP,
  title={A Glimpse of Answer Set Programming},
  author={Christian Anger and Kathrin Konczak and Thomas Linke and Torsten Schaub},
  year={2005},
  volume={19},
  pages={12-}
}

@article{knuth1975analysis,
  title={An analysis of alpha-beta pruning},
  author={Knuth, Donald E and Moore, Ronald W},
  journal={Artificial intelligence},
  volume={6},
  number={4},
  pages={293--326},
  year={1975},
  publisher={Elsevier}
}

@incollection{shanahan1999event,
  title={The event calculus explained},
  author={Shanahan, Murray},
  booktitle={Artificial intelligence today},
  pages={409--430},
  year={1999},
  publisher={Springer}
}