
@incollection{schockaert_combinatorial_2016,
	address = {Cham},
	title = {Combinatorial {Games}: {From} {Theoretical} {Solving} to {AI} {Algorithms}},
	volume = {9858},
	isbn = {978-3-319-45855-7 978-3-319-45856-4},
	shorttitle = {Combinatorial {Games}},
	url = {http://link.springer.com/10.1007/978-3-319-45856-4_1},
	urldate = {2020-07-15},
	booktitle = {Scalable {Uncertainty} {Management}},
	publisher = {Springer International Publishing},
	author = {Duchêne, Eric},
	editor = {Schockaert, Steven and Senellart, Pierre},
	year = {2016},
	doi = {10.1007/978-3-319-45856-4_1},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {3--17},
	file = {Submitted Version:/home/lks/Zotero/storage/ZNJY9V64/Duchêne - 2016 - Combinatorial Games From Theoretical Solving to A.pdf:application/pdf}
}

@article{watkins_q-learning_1992,
	title = {Q-learning},
	volume = {8},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/BF00992698},
	doi = {10.1007/BF00992698},
	language = {en},
	number = {3-4},
	urldate = {2020-07-15},
	journal = {Machine Learning},
	author = {Watkins, Christopher J. C. H. and Dayan, Peter},
	month = may,
	year = {1992},
	pages = {279--292},
	file = {Full Text:/home/lks/Zotero/storage/97RXL5K5/Watkins and Dayan - 1992 - Q-learning.pdf:application/pdf}
}

@inproceedings{cruz_comparing_2013,
	address = {Ipojuca, Brazil},
	title = {Comparing {Strategies} to {Play} a 2-{Sided} {Dominoes} {Game}},
	isbn = {978-1-4799-3194-1},
	url = {http://ieeexplore.ieee.org/document/6855868/},
	doi = {10.1109/BRICS-CCI-CBIC.2013.59},
	urldate = {2020-07-15},
	booktitle = {2013 {BRICS} {Congress} on {Computational} {Intelligence} and 11th {Brazilian} {Congress} on {Computational} {Intelligence}},
	publisher = {IEEE},
	author = {Cruz, Andre R. da and Guimaraes, Frederico G. and Takahashi, Ricardo H.C.},
	month = sep,
	year = {2013},
	pages = {310--316}
}

@book{lifschitz_answer_2019,
	title = {Answer {Set} {Programming}},
	isbn = {978-3-030-24658-7},
	url = {https://doi.org/10.1007/978-3-030-24658-7},
	language = {English},
	urldate = {2020-07-15},
	author = {Lifschitz, Vladimir},
	year = {2019},
	note = {OCLC: 1119007947}
}

@incollection{pisano_combinatorial_2015,
	address = {Dordrecht},
	title = {Combinatorial {Games} and {Machines}},
	volume = {27},
	isbn = {978-94-017-9644-6 978-94-017-9645-3},
	url = {http://link.springer.com/10.1007/978-94-017-9645-3_24},
	urldate = {2020-07-16},
	booktitle = {A {Bridge} between {Conceptual} {Frameworks}},
	publisher = {Springer Netherlands},
	author = {Rougetet, Lisa},
	editor = {Pisano, Raffaele},
	year = {2015},
	doi = {10.1007/978-94-017-9645-3_24},
	note = {Series Title: History of Mechanism and Machine Science},
	pages = {475--494}
}

@article{mnih_playing_2013,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	urldate = {2020-07-16},
	journal = {arXiv:1312.5602 [cs]},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.5602},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/lks/Zotero/storage/3AB8Y24Q/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/home/lks/Zotero/storage/6N9XWHG8/1312.html:text/html}
}

@inproceedings{lloyd_practical_1994,
	title = {Practical {Advtanages} of {Declarative} {Programming}},
	booktitle = {1994 {Joint} {Conference} on {Declarative} {Programming}, {GULP}-{PRODE}'94 {Peñiscola}, {Spain}, {September} 19-22, 1994, {Volume} 1},
	author = {Lloyd, John W.},
	editor = {Alpuente, María and Barbuti, Roberto and Ramos, Isidro},
	year = {1994},
	pages = {18--30}
}

@book{russell_artificial_2010,
	address = {Upper Saddle River},
	edition = {3rd ed},
	series = {Prentice {Hall} series in artificial intelligence},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-604259-4},
	shorttitle = {Artificial intelligence},
	publisher = {Prentice Hall},
	author = {Russell, Stuart J. and Norvig, Peter and Davis, Ernest},
	year = {2010},
	keywords = {Artificial intelligence}
}

@incollection{wiering_reinforcement_2012,
	address = {Berlin, Heidelberg},
	title = {Reinforcement {Learning} in {Games}},
	volume = {12},
	isbn = {978-3-642-27644-6 978-3-642-27645-3},
	url = {http://link.springer.com/10.1007/978-3-642-27645-3_17},
	urldate = {2020-07-27},
	booktitle = {Reinforcement {Learning}},
	publisher = {Springer Berlin Heidelberg},
	author = {Szita, István},
	editor = {Wiering, Marco and van Otterlo, Martijn},
	year = {2012},
	doi = {10.1007/978-3-642-27645-3_17},
	note = {Series Title: Adaptation, Learning, and Optimization},
	pages = {539--577}
}

@article{francois-lavet_introduction_2018,
	title = {An {Introduction} to {Deep} {Reinforcement} {Learning}},
	volume = {11},
	issn = {1935-8237, 1935-8245},
	url = {http://arxiv.org/abs/1811.12560},
	doi = {10.1561/2200000071},
	abstract = {Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.},
	number = {3-4},
	urldate = {2020-07-28},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Francois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G. and Pineau, Joelle},
	year = {2018},
	note = {arXiv: 1811.12560},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {219--354},
	file = {arXiv Fulltext PDF:/home/lks/Zotero/storage/RUSCKCVG/Francois-Lavet et al. - 2018 - An Introduction to Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/home/lks/Zotero/storage/7M3SMGT3/1811.html:text/html}
}

@book{sutton_reinforcement_2018,
	address = {Cambridge, Massachusetts},
	edition = {Second edition},
	series = {Adaptive computation and machine learning series},
	title = {Reinforcement learning: an introduction},
	isbn = {978-0-262-03924-6},
	shorttitle = {Reinforcement learning},
	abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
	publisher = {The MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {2018},
	keywords = {Reinforcement learning}
}

@book{olivas_handbook_2010,
	title = {Handbook of {Research} on {Machine} {Learning} {Applications} and {Trends}: {Algorithms}, {Methods}, and {Techniques}},
	isbn = {978-1-60566-766-9 978-1-60566-767-6},
	shorttitle = {Handbook of {Research} on {Machine} {Learning} {Applications} and {Trends}},
	url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-60566-766-9},
	urldate = {2020-07-30},
	publisher = {IGI Global},
	editor = {Olivas, Emilio Soria and Guerrero, José David Martín and Martinez-Sober, Marcelino and Magdalena-Benedito, Jose Rafael and Serrano López, Antonio José},
	year = {2010},
	doi = {10.4018/978-1-60566-766-9},
	file = {Submitted Version:/home/lks/Zotero/storage/YNZBYYA8/Olivas et al. - 2010 - Handbook of Research on Machine Learning Applicati.pdf:application/pdf}
}

@incollection{noauthor_notitle_nodate
}

@incollection{olivas_transfer_2010,
	title = {Transfer {Learning}},
	isbn = {978-1-60566-766-9 978-1-60566-767-6},
	url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-60566-766-9},
	urldate = {2020-07-30},
	booktitle = {Handbook of {Research} on {Machine} {Learning} {Applications} and {Trends}: {Algorithms}, {Methods}, and {Techniques}},
	publisher = {IGI Global},
	author = {Torrey, Lisa and Shavik, Jude},
	editor = {Olivas, Emilio Soria and Guerrero, José David Martín and Martinez-Sober, Marcelino and Magdalena-Benedito, Jose Rafael and Serrano López, Antonio José},
	year = {2010},
	doi = {10.4018/978-1-60566-766-9.ch011}
}

@article{browne_survey_2012,
	title = {A {Survey} of {Monte} {Carlo} {Tree} {Search} {Methods}},
	volume = {4},
	issn = {1943-068X, 1943-0698},
	url = {http://ieeexplore.ieee.org/document/6145622/},
	doi = {10.1109/TCIAIG.2012.2186810},
	number = {1},
	urldate = {2020-07-30},
	journal = {IEEE Transactions on Computational Intelligence and AI in Games},
	author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
	month = mar,
	year = {2012},
	pages = {1--43},
	file = {Accepted Version:/home/lks/Zotero/storage/EZJJVWJ7/Browne et al. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf:application/pdf}
}

@article{silver_mastering_2016,
	title = {Mastering the game of {Go} with deep neural networks and tree search},
	volume = {529},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	language = {en},
	number = {7587},
	urldate = {2020-08-25},
	journal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	month = jan,
	year = {2016},
	pages = {484--489}
}

@article{bouton_nim_1901,
	title = {Nim, {A} {Game} with a {Complete} {Mathematical} {Theory}},
	volume = {3},
	issn = {0003486X},
	url = {https://www.jstor.org/stable/1967631?origin=crossref},
	doi = {10.2307/1967631},
	number = {1/4},
	urldate = {2020-09-01},
	journal = {The Annals of Mathematics},
	author = {Bouton, Charles L.},
	year = {1901},
	pages = {35}
}

@incollection{hutchison_efficient_2007,
	address = {Berlin, Heidelberg},
	title = {Efficient {Selectivity} and {Backup} {Operators} in {Monte}-{Carlo} {Tree} {Search}},
	volume = {4630},
	isbn = {978-3-540-75537-1 978-3-540-75538-8},
	url = {http://link.springer.com/10.1007/978-3-540-75538-8_7},
	urldate = {2020-09-01},
	booktitle = {Computers and {Games}},
	publisher = {Springer Berlin Heidelberg},
	author = {Coulom, Rémi},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and van den Herik, H. Jaap and Ciancarini, Paolo and Donkers, H. H. L. M.},
	year = {2007},
	doi = {10.1007/978-3-540-75538-8_7},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {72--83},
	file = {Submitted Version:/home/lks/Zotero/storage/MDKIIJGN/Coulom - 2007 - Efficient Selectivity and Backup Operators in Mont.pdf:application/pdf}
}

@article{love_general_2008,
	title = {General {Game} {Playing}: {Game} {Description} {Language} {Specification}},
	url = {http://logic.stanford.edu/classes/cs227/2013/readings/gdl_spec.pdf},
	journal = {Stanford University},
	author = {Love, Nathaniel and Hinrichs, Timothy and Haley, David and Schkufza, Eric and Genesereth, Michael},
	year = {2008}
}

@article{gebser_clingo_2014,
	title = {Clingo = {ASP} + {Control}: {Preliminary} {Report}},
	shorttitle = {Clingo = {ASP} + {Control}},
	url = {http://arxiv.org/abs/1405.3694},
	abstract = {We present the new ASP system clingo 4. Unlike its predecessors, being mere monolithic combinations of the grounder gringo with the solver clasp, the new clingo 4 series offers high-level constructs for realizing complex reasoning processes. Among others, such processes feature advanced forms of search, as in optimization or theory solving, or even interact with an environment, as in robotics or query-answering. Common to them is that the problem specification evolves during the reasoning process, either because data or constraints are added, deleted, or replaced. In fact, clingo 4 carries out such complex reasoning within a single integrated ASP grounding and solving process. This avoids redundancies in relaunching grounder and solver programs and benefits from the solver's learning capacities. clingo 4 accomplishes this by complementing ASP's declarative input language by control capacities expressed via the embedded scripting languages lua and python. On the declarative side, clingo 4 offers a new directive that allows for structuring logic programs into named and parameterizable subprograms. The grounding and integration of these subprograms into the solving process is completely modular and fully controllable from the procedural side, viz. the scripting languages. By strictly separating logic and control programs, clingo 4 also abolishes the need for dedicated systems for incremental and reactive reasoning, like iclingo and oclingo, respectively, and its flexibility goes well beyond the advanced yet still rigid solving processes of the latter.},
	urldate = {2020-09-02},
	journal = {arXiv:1405.3694 [cs]},
	author = {Gebser, Martin and Kaminski, Roland and Kaufmann, Benjamin and Schaub, Torsten},
	month = may,
	year = {2014},
	note = {arXiv: 1405.3694},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/lks/Zotero/storage/MU89B3II/Gebser et al. - 2014 - Clingo = ASP + Control Preliminary Report.pdf:application/pdf;arXiv.org Snapshot:/home/lks/Zotero/storage/KCD2CHHX/1405.html:text/html}
}

@book{berlekamp_winning_2001,
	edition = {2},
	title = {Winning {Ways} for {Your} {Mathematical} {Plays}},
	isbn = {978-0-429-48733-0},
	url = {https://www.taylorfrancis.com/books/9780429945557},
	language = {en},
	urldate = {2020-09-02},
	publisher = {A K Peters/CRC Press},
	author = {Berlekamp, Elwyn R. and Conway, John H. and Guy, Richard K.},
	year = {2001},
	doi = {10.1201/9780429487330}
}

@article{silver_mastering_2017,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	language = {en},
	number = {7676},
	urldate = {2020-09-03},
	journal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	month = oct,
	year = {2017},
	pages = {354--359},
	file = {Submitted Version:/home/lks/Zotero/storage/6JMG5MLM/Silver et al. - 2017 - Mastering the game of Go without human knowledge.pdf:application/pdf}
}
